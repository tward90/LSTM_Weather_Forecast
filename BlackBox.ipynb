{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 27140 entries, 0 to 27139\nData columns (total 16 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   Unnamed: 0        27140 non-null  int64  \n 1   Date              27140 non-null  object \n 2   temp              27140 non-null  float64\n 3   dewp              27140 non-null  float64\n 4   slp               27140 non-null  float64\n 5   visib             27140 non-null  float64\n 6   wdsp              27140 non-null  float64\n 7   max               27140 non-null  float64\n 8   min               27140 non-null  float64\n 9   fog               27140 non-null  float64\n 10  rain_drizzle      27140 non-null  float64\n 11  snow_ice_pellets  27140 non-null  float64\n 12  hail              27140 non-null  float64\n 13  thunder           27140 non-null  float64\n 14  year sin          27140 non-null  float64\n 15  year cos          27140 non-null  float64\ndtypes: float64(14), int64(1), object(1)\nmemory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"model_data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df.drop([\"Date\"], axis=1).values\n",
    "values = values.astype(\"float32\")\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       var1(t-2)  var2(t-2)  var3(t-2)  ...  var13(t)  var14(t)  var15(t)\n",
       "2       0.000000   0.478950   0.551425  ...       0.0  0.470697  0.000859\n",
       "3       0.000037   0.593028   0.684015  ...       0.0  0.462115  0.001437\n",
       "4       0.000074   0.645994   0.775712  ...       1.0  0.453544  0.002163\n",
       "5       0.000111   0.666365   0.812887  ...       0.0  0.444987  0.003036\n",
       "6       0.000147   0.617474   0.686493  ...       0.0  0.436447  0.004055\n",
       "...          ...        ...        ...  ...       ...       ...       ...\n",
       "27135   0.999779   0.741602   0.658736  ...       0.0  0.998481  0.461059\n",
       "27136   0.999816   0.693526   0.696654  ...       0.0  0.997738  0.452490\n",
       "27137   0.999853   0.736170   0.759851  ...       0.0  0.996847  0.443935\n",
       "27138   0.999889   0.756813   0.784634  ...       0.0  0.995809  0.435397\n",
       "27139   0.999926   0.748936   0.765799  ...       0.0  0.994624  0.426877\n",
       "\n",
       "[27138 rows x 45 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>var1(t-2)</th>\n      <th>var2(t-2)</th>\n      <th>var3(t-2)</th>\n      <th>var4(t-2)</th>\n      <th>var5(t-2)</th>\n      <th>var6(t-2)</th>\n      <th>var7(t-2)</th>\n      <th>var8(t-2)</th>\n      <th>var9(t-2)</th>\n      <th>var10(t-2)</th>\n      <th>var11(t-2)</th>\n      <th>var12(t-2)</th>\n      <th>var13(t-2)</th>\n      <th>var14(t-2)</th>\n      <th>var15(t-2)</th>\n      <th>var1(t-1)</th>\n      <th>var2(t-1)</th>\n      <th>var3(t-1)</th>\n      <th>var4(t-1)</th>\n      <th>var5(t-1)</th>\n      <th>var6(t-1)</th>\n      <th>var7(t-1)</th>\n      <th>var8(t-1)</th>\n      <th>var9(t-1)</th>\n      <th>var10(t-1)</th>\n      <th>var11(t-1)</th>\n      <th>var12(t-1)</th>\n      <th>var13(t-1)</th>\n      <th>var14(t-1)</th>\n      <th>var15(t-1)</th>\n      <th>var1(t)</th>\n      <th>var2(t)</th>\n      <th>var3(t)</th>\n      <th>var4(t)</th>\n      <th>var5(t)</th>\n      <th>var6(t)</th>\n      <th>var7(t)</th>\n      <th>var8(t)</th>\n      <th>var9(t)</th>\n      <th>var10(t)</th>\n      <th>var11(t)</th>\n      <th>var12(t)</th>\n      <th>var13(t)</th>\n      <th>var14(t)</th>\n      <th>var15(t)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.478950</td>\n      <td>0.551425</td>\n      <td>0.580982</td>\n      <td>0.372414</td>\n      <td>0.169381</td>\n      <td>0.469502</td>\n      <td>0.447147</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.487884</td>\n      <td>0.000147</td>\n      <td>0.000037</td>\n      <td>0.593028</td>\n      <td>0.684015</td>\n      <td>0.558163</td>\n      <td>0.396552</td>\n      <td>0.351792</td>\n      <td>0.529695</td>\n      <td>0.596347</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.479287</td>\n      <td>0.000429</td>\n      <td>0.000074</td>\n      <td>0.645994</td>\n      <td>0.775712</td>\n      <td>0.512520</td>\n      <td>0.362069</td>\n      <td>0.221498</td>\n      <td>0.591092</td>\n      <td>0.662809</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.470697</td>\n      <td>0.000859</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000037</td>\n      <td>0.593028</td>\n      <td>0.684015</td>\n      <td>0.558163</td>\n      <td>0.396552</td>\n      <td>0.351792</td>\n      <td>0.529695</td>\n      <td>0.596347</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.479287</td>\n      <td>0.000429</td>\n      <td>0.000074</td>\n      <td>0.645994</td>\n      <td>0.775712</td>\n      <td>0.512520</td>\n      <td>0.362069</td>\n      <td>0.221498</td>\n      <td>0.591092</td>\n      <td>0.662809</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.470697</td>\n      <td>0.000859</td>\n      <td>0.000111</td>\n      <td>0.666365</td>\n      <td>0.812887</td>\n      <td>0.455467</td>\n      <td>0.296552</td>\n      <td>0.407166</td>\n      <td>0.577849</td>\n      <td>0.730627</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.462115</td>\n      <td>0.001437</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000074</td>\n      <td>0.645994</td>\n      <td>0.775712</td>\n      <td>0.512520</td>\n      <td>0.362069</td>\n      <td>0.221498</td>\n      <td>0.591092</td>\n      <td>0.662809</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.470697</td>\n      <td>0.000859</td>\n      <td>0.000111</td>\n      <td>0.666365</td>\n      <td>0.812887</td>\n      <td>0.455467</td>\n      <td>0.296552</td>\n      <td>0.407166</td>\n      <td>0.577849</td>\n      <td>0.730627</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.462115</td>\n      <td>0.001437</td>\n      <td>0.000147</td>\n      <td>0.617474</td>\n      <td>0.686493</td>\n      <td>0.225357</td>\n      <td>0.324138</td>\n      <td>0.315961</td>\n      <td>0.577849</td>\n      <td>0.608554</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.453544</td>\n      <td>0.002163</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.000111</td>\n      <td>0.666365</td>\n      <td>0.812887</td>\n      <td>0.455467</td>\n      <td>0.296552</td>\n      <td>0.407166</td>\n      <td>0.577849</td>\n      <td>0.730627</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.462115</td>\n      <td>0.001437</td>\n      <td>0.000147</td>\n      <td>0.617474</td>\n      <td>0.686493</td>\n      <td>0.225357</td>\n      <td>0.324138</td>\n      <td>0.315961</td>\n      <td>0.577849</td>\n      <td>0.608554</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.453544</td>\n      <td>0.002163</td>\n      <td>0.000184</td>\n      <td>0.640561</td>\n      <td>0.798017</td>\n      <td>0.204437</td>\n      <td>0.175862</td>\n      <td>0.201954</td>\n      <td>0.615169</td>\n      <td>0.623474</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.444987</td>\n      <td>0.003036</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.000147</td>\n      <td>0.617474</td>\n      <td>0.686493</td>\n      <td>0.225357</td>\n      <td>0.324138</td>\n      <td>0.315961</td>\n      <td>0.577849</td>\n      <td>0.608554</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.453544</td>\n      <td>0.002163</td>\n      <td>0.000184</td>\n      <td>0.640561</td>\n      <td>0.798017</td>\n      <td>0.204437</td>\n      <td>0.175862</td>\n      <td>0.201954</td>\n      <td>0.615169</td>\n      <td>0.623474</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.444987</td>\n      <td>0.003036</td>\n      <td>0.000221</td>\n      <td>0.648710</td>\n      <td>0.837670</td>\n      <td>0.303328</td>\n      <td>0.017241</td>\n      <td>0.192182</td>\n      <td>0.540530</td>\n      <td>0.703499</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.436447</td>\n      <td>0.004055</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27135</th>\n      <td>0.999779</td>\n      <td>0.741602</td>\n      <td>0.658736</td>\n      <td>0.548273</td>\n      <td>0.320690</td>\n      <td>0.160261</td>\n      <td>0.701605</td>\n      <td>0.683425</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.999526</td>\n      <td>0.478229</td>\n      <td>0.999816</td>\n      <td>0.693526</td>\n      <td>0.696654</td>\n      <td>0.504913</td>\n      <td>0.315172</td>\n      <td>0.087296</td>\n      <td>0.705939</td>\n      <td>0.623745</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.999077</td>\n      <td>0.469640</td>\n      <td>0.999853</td>\n      <td>0.736170</td>\n      <td>0.759851</td>\n      <td>0.515562</td>\n      <td>0.297241</td>\n      <td>0.067101</td>\n      <td>0.730979</td>\n      <td>0.658739</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.998481</td>\n      <td>0.461059</td>\n    </tr>\n    <tr>\n      <th>27136</th>\n      <td>0.999816</td>\n      <td>0.693526</td>\n      <td>0.696654</td>\n      <td>0.504913</td>\n      <td>0.315172</td>\n      <td>0.087296</td>\n      <td>0.705939</td>\n      <td>0.623745</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.999077</td>\n      <td>0.469640</td>\n      <td>0.999853</td>\n      <td>0.736170</td>\n      <td>0.759851</td>\n      <td>0.515562</td>\n      <td>0.297241</td>\n      <td>0.067101</td>\n      <td>0.730979</td>\n      <td>0.658739</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.998481</td>\n      <td>0.461059</td>\n      <td>0.999889</td>\n      <td>0.756813</td>\n      <td>0.784634</td>\n      <td>0.519367</td>\n      <td>0.311034</td>\n      <td>0.103583</td>\n      <td>0.704254</td>\n      <td>0.739850</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.997738</td>\n      <td>0.452490</td>\n    </tr>\n    <tr>\n      <th>27137</th>\n      <td>0.999853</td>\n      <td>0.736170</td>\n      <td>0.759851</td>\n      <td>0.515562</td>\n      <td>0.297241</td>\n      <td>0.067101</td>\n      <td>0.730979</td>\n      <td>0.658739</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.998481</td>\n      <td>0.461059</td>\n      <td>0.999889</td>\n      <td>0.756813</td>\n      <td>0.784634</td>\n      <td>0.519367</td>\n      <td>0.311034</td>\n      <td>0.103583</td>\n      <td>0.704254</td>\n      <td>0.739850</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.997738</td>\n      <td>0.452490</td>\n      <td>0.999926</td>\n      <td>0.748936</td>\n      <td>0.765799</td>\n      <td>0.475626</td>\n      <td>0.297241</td>\n      <td>0.106189</td>\n      <td>0.731461</td>\n      <td>0.715978</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.996847</td>\n      <td>0.443935</td>\n    </tr>\n    <tr>\n      <th>27138</th>\n      <td>0.999889</td>\n      <td>0.756813</td>\n      <td>0.784634</td>\n      <td>0.519367</td>\n      <td>0.311034</td>\n      <td>0.103583</td>\n      <td>0.704254</td>\n      <td>0.739850</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.997738</td>\n      <td>0.452490</td>\n      <td>0.999926</td>\n      <td>0.748936</td>\n      <td>0.765799</td>\n      <td>0.475626</td>\n      <td>0.297241</td>\n      <td>0.106189</td>\n      <td>0.731461</td>\n      <td>0.715978</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.996847</td>\n      <td>0.443935</td>\n      <td>0.999963</td>\n      <td>0.749208</td>\n      <td>0.754399</td>\n      <td>0.454327</td>\n      <td>0.311034</td>\n      <td>0.102280</td>\n      <td>0.745425</td>\n      <td>0.680441</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.995809</td>\n      <td>0.435397</td>\n    </tr>\n    <tr>\n      <th>27139</th>\n      <td>0.999926</td>\n      <td>0.748936</td>\n      <td>0.765799</td>\n      <td>0.475626</td>\n      <td>0.297241</td>\n      <td>0.106189</td>\n      <td>0.731461</td>\n      <td>0.715978</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.996847</td>\n      <td>0.443935</td>\n      <td>0.999963</td>\n      <td>0.749208</td>\n      <td>0.754399</td>\n      <td>0.454327</td>\n      <td>0.311034</td>\n      <td>0.102280</td>\n      <td>0.745425</td>\n      <td>0.680441</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.995809</td>\n      <td>0.435397</td>\n      <td>1.000000</td>\n      <td>0.797284</td>\n      <td>0.865923</td>\n      <td>0.434929</td>\n      <td>0.317241</td>\n      <td>0.057980</td>\n      <td>0.634671</td>\n      <td>0.878470</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.994624</td>\n      <td>0.426877</td>\n    </tr>\n  </tbody>\n</table>\n<p>27138 rows × 45 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "series_to_supervised(scaled, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "reframed.drop(reframed.columns[[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframe_values = reframed.values\n",
    "X = reframe_values[:,:-1]\n",
    "y = reframe_values[:, -1]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False)\n",
    "# X_train = np.expand_dims(X_train, axis=1)\n",
    "# X_test = np.expand_dims(X_test, axis=1)\n",
    "# y_train = np.expand_dims(y_train, axis=1)\n",
    "# y_test = np.expand_dims(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/tyler/Documents/Rice/Projects/Project_3/Project03_Team01/<ipython-input-13-50cf1ac94ecb>'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-50cf1ac94ecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     best_run, best_model = optim.minimize(model=create_model,\n\u001b[0m\u001b[1;32m     28\u001b[0m                                           \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                           \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/WeatherML/lib/python3.8/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mreturn_space\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpair\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0msearch\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \"\"\"\n\u001b[0;32m---> 59\u001b[0;31m     best_run, space = base_minimizer(model=model,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                      \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                                      \u001b[0mfunctions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/WeatherML/lib/python3.8/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mmodel_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_model_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mmodel_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hyperopt_model_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtemp_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./temp_model.py'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mwrite_temp_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/WeatherML/lib/python3.8/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mget_hyperopt_model_string\u001b[0;34m(model, data, functions, notebook_name, verbose, stack)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mcalling_script_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalling_script_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/tyler/Documents/Rice/Projects/Project_3/Project03_Team01/<ipython-input-13-50cf1ac94ecb>'"
     ]
    }
   ],
   "source": [
    "def data():\n",
    "    X_train = np.expand_dims(X_train, axis=1)\n",
    "    X_test = np.expand_dims(X_test, axis=1)\n",
    "    y_train = np.expand_dims(y_train, axis=1)\n",
    "    y_test = np.expand_dims(y_test, axis=1)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def create_model(X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM({{uniform(10,50)}}, \n",
    "            input_shape=(X_train.shape[1], \n",
    "            X_train.shape[2])\n",
    "            ))\n",
    "    model.add(Dense({{choice([10, 20, 50, 100])}}))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss={{choice([\"mae\", 'categorical_crossentropy'])}}, \n",
    "                    optimizer={{choice([\"adam\", \"sgd\", \"rmsprop\"])}}, \n",
    "                    metrics=[\"mse\"])\n",
    "\n",
    "    result = model.fit(X_train, y_train, epochs=25, batch_size=60, validation_split=0.1, verbose=2, shuffle=False)\n",
    "\n",
    "    validation_acc=np.amax(result.history['val_acc'])\n",
    "    print('Best Validation acc of epoch:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model':model}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials())\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = data()\n",
    "    print('Evaluation of best performing model:')\n",
    "    print(best_model.evaluate(X_test, y_test))\n",
    "    print(\"Best Performing Model Hyper-Parameters:\")\n",
    "    print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    X_train = np.expand_dims(X_train, axis=1)\n",
    "    X_test = np.expand_dims(X_test, axis=1)\n",
    "    y_train = np.expand_dims(y_train, axis=1)\n",
    "    y_test = np.expand_dims(y_test, axis=1)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def create_model(X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM({{uniform(10,50)}}, \n",
    "            input_shape=(X_train.shape[1], \n",
    "            X_train.shape[2])\n",
    "            ))\n",
    "    model.add(Dense({{choice([10, 20, 50, 100])}}))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss={{choice([\"mae\", 'categorical_crossentropy'])}}, \n",
    "                    optimizer={{choice([\"adam\", \"sgd\", \"rmsprop\"])}}, \n",
    "                    metrics=[\"mse\"])\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy = score[1]\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    best_run = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"mse\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_mse\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.title('Train vs. Test MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = pred - y_test\n",
    "plt.plot(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(residual[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "X_test_reshape = X_test.reshape((X_test.shape[0], X_test.shape[2]))\n",
    "inv = np.concatenate((pred, X_test_reshape[:, 1:]), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "inv_scale = scaler.inverse_transform(inv)\n",
    "\n",
    "y_inv = np.concatenate((y_test, X_test_reshape[:, 1:]), axis=1)\n",
    "y_inv = scaler.inverse_transform(y_inv)\n",
    "y_inv\n",
    "\n",
    "# y_test.shape\n",
    "inv_scale[0].shape\n",
    "# scaler.inverse_transform(pred)\n",
    "predictions = pd.DataFrame({\"Prediction\": inv_scale[:,:1].flatten(), \"Actual\": y_inv[:,:1].flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('WeatherML': conda)",
   "display_name": "Python 3.8.5 64-bit ('WeatherML': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fa0a90ea388e647b6806305426e0b9939b78a8fc99087e1c6cd6e6ae226ce148"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}