{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('WeatherML': conda)",
   "display_name": "Python 3.8.5 64-bit ('WeatherML': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fa0a90ea388e647b6806305426e0b9939b78a8fc99087e1c6cd6e6ae226ce148"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from matplotlib import pyplot as plt\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.layers import LSTM\n",
    "# from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "\n",
    "# from hyperas import optim\n",
    "# from hyperas.distributions import choice, uniform\n",
    "# from hyperopt import Trials, STATUS_OK, tpe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"model_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    df = pd.read_csv(\"model_data.csv\")\n",
    "\n",
    "    def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "        n_vars = 1 if type(data) is list else data.shape[1]\n",
    "        df = pd.DataFrame(data)\n",
    "        cols, names = list(), list()\n",
    "        # input sequence (t-n, ... t-1)\n",
    "        for i in range(n_in, 0, -1):\n",
    "            cols.append(df.shift(i))\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "        # forecast sequence (t, t+1, ... t+n)\n",
    "        for i in range(0, n_out):\n",
    "            cols.append(df.shift(-i))\n",
    "            if i == 0:\n",
    "                names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "            else:\n",
    "                names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "        # put it all together\n",
    "        agg = pd.concat(cols, axis=1)\n",
    "        agg.columns = names\n",
    "        # drop rows with NaN values\n",
    "        if dropnan:\n",
    "            agg.dropna(inplace=True)\n",
    "        return agg\n",
    "\n",
    "    values = df.drop([\"Date\"], axis=1).values\n",
    "    values = values.astype(\"float32\")\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(values)\n",
    "\n",
    "    reframed = series_to_supervised(scaled, 1, 1)\n",
    "    reframed.drop(reframed.columns[[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    reframe_values = reframed.values\n",
    "    X = reframe_values[:,:-1]\n",
    "    y = reframe_values[:, -1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False)\n",
    "    X_train = np.expand_dims(X_train, axis=1)\n",
    "    X_test = np.expand_dims(X_test, axis=1)\n",
    "    y_train = np.expand_dims(y_train, axis=1)\n",
    "    y_test = np.expand_dims(y_test, axis=1)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "    #Create a specific train split before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(20354, 1, 15)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6785, 1, 15)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "import numpy as numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, X_test, y_train, y_test):\n",
    "\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.layers import Dense\n",
    "        from tensorflow.keras.layers import LSTM\n",
    "        from hyperas.distributions import choice, uniform\n",
    "        from hyperopt import STATUS_OK\n",
    "\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM({{choice([5, 10, 25, 50, 75, 100])}}, \n",
    "                input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "                )\n",
    "\n",
    "        model.add(Dense({{choice([10, 20, 50, 100])}}))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss={{choice([\"mae\", \"mse\"])}}, \n",
    "                    optimizer={{choice([\"adam\", \"sgd\", \"rmsprop\"])}}, \n",
    "                    metrics=[\"mae\", \"mse\"]\n",
    "                    )\n",
    "        e_stop =  tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n",
    "\n",
    "        result = model.fit(X_train, y_train, epochs=25, batch_size=60, validation_split=0.1, verbose=2, callbacks = [e_stop], shuffle=False)\n",
    "\n",
    "        # print(result.history)\n",
    "\n",
    "        validation_loss = np.amin(result.history['val_loss'])\n",
    "        print('Best Validation loss of epoch:', validation_loss)\n",
    "        return {'loss': validation_loss, 'status': STATUS_OK, 'model':model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n",
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import MinMaxScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as numpy\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import LSTM\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import STATUS_OK\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'LSTM': hp.choice('LSTM', [5, 10, 25, 50, 75, 100]),\n",
      "        'Dense': hp.choice('Dense', [10, 20, 50, 100]),\n",
      "        'loss': hp.choice('loss', [\"mae\", \"mse\"]),\n",
      "        'optimizer': hp.choice('optimizer', [\"adam\", \"sgd\", \"rmsprop\"]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: import pandas as pd\n",
      "   3: import numpy as np\n",
      "   4: from sklearn.preprocessing import MinMaxScaler\n",
      "   5: from sklearn.model_selection import train_test_split\n",
      "   6: \n",
      "   7: df = pd.read_csv(\"model_data.csv\")\n",
      "   8: \n",
      "   9: def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
      "  10:     n_vars = 1 if type(data) is list else data.shape[1]\n",
      "  11:     df = pd.DataFrame(data)\n",
      "  12:     cols, names = list(), list()\n",
      "  13:     # input sequence (t-n, ... t-1)\n",
      "  14:     for i in range(n_in, 0, -1):\n",
      "  15:         cols.append(df.shift(i))\n",
      "  16:         names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
      "  17:     # forecast sequence (t, t+1, ... t+n)\n",
      "  18:     for i in range(0, n_out):\n",
      "  19:         cols.append(df.shift(-i))\n",
      "  20:         if i == 0:\n",
      "  21:             names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
      "  22:         else:\n",
      "  23:             names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
      "  24:     # put it all together\n",
      "  25:     agg = pd.concat(cols, axis=1)\n",
      "  26:     agg.columns = names\n",
      "  27:     # drop rows with NaN values\n",
      "  28:     if dropnan:\n",
      "  29:         agg.dropna(inplace=True)\n",
      "  30:     return agg\n",
      "  31: \n",
      "  32: values = df.drop([\"Date\"], axis=1).values\n",
      "  33: values = values.astype(\"float32\")\n",
      "  34: scaler = MinMaxScaler(feature_range=(0, 1))\n",
      "  35: scaled = scaler.fit_transform(values)\n",
      "  36: \n",
      "  37: reframed = series_to_supervised(scaled, 1, 1)\n",
      "  38: reframed.drop(reframed.columns[[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]], axis=1, inplace=True)\n",
      "  39: \n",
      "  40: \n",
      "  41: reframe_values = reframed.values\n",
      "  42: X = reframe_values[:,:-1]\n",
      "  43: y = reframe_values[:, -1]\n",
      "  44: \n",
      "  45: X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False)\n",
      "  46: X_train = np.expand_dims(X_train, axis=1)\n",
      "  47: X_test = np.expand_dims(X_test, axis=1)\n",
      "  48: y_train = np.expand_dims(y_train, axis=1)\n",
      "  49: y_test = np.expand_dims(y_test, axis=1)\n",
      "  50: \n",
      "  51: \n",
      "  52: \n",
      "  53: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "  1: def keras_fmin_fnct(space):\n",
      "  2: \n",
      "  3: \n",
      "  4: \n",
      "  5: \n",
      "  6:         model = Sequential()\n",
      "  7:         model.add(LSTM(space['LSTM'], \n",
      "  8:                 input_shape=(X_train.shape[1], X_train.shape[2]))\n",
      "  9:                 )\n",
      " 10: \n",
      " 11:         model.add(Dense(space['Dense']))\n",
      " 12:         model.add(Dense(1))\n",
      " 13:         model.compile(loss=space['loss'], \n",
      " 14:                     optimizer=space['optimizer'], \n",
      " 15:                     metrics=[\"mae\", \"mse\"]\n",
      " 16:                     )\n",
      " 17:         e_stop =  tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n",
      " 18: \n",
      " 19:         result = model.fit(X_train, y_train, epochs=25, batch_size=60, validation_split=0.1, verbose=2, callbacks = [e_stop], shuffle=False)\n",
      " 20: \n",
      " 21:         # print(result.history)\n",
      " 22: \n",
      " 23:         validation_loss = np.amin(result.history['val_loss'])\n",
      " 24:         print('Best Validation loss of epoch:', validation_loss)\n",
      " 25:         return {'loss': validation_loss, 'status': STATUS_OK, 'model':model}\n",
      " 26: \n",
      "Epoch 1/25\n",
      "306/306 - 1s - loss: 1.1679e-04 - mae: 0.0087 - mse: 1.1679e-04 - val_loss: 0.0039 - val_mae: 0.0574 - val_mse: 0.0039\n",
      "\n",
      "Epoch 2/25\n",
      "306/306 - 1s - loss: 0.0131 - mae: 0.0426 - mse: 0.0131 - val_loss: 0.0032 - val_mae: 0.0519 - val_mse: 0.0032\n",
      "\n",
      "Epoch 3/25\n",
      "306/306 - 1s - loss: 0.0128 - mae: 0.0410 - mse: 0.0128 - val_loss: 0.0031 - val_mae: 0.0509 - val_mse: 0.0031\n",
      "\n",
      "Epoch 4/25\n",
      "306/306 - 1s - loss: 0.0126 - mae: 0.0403 - mse: 0.0126 - val_loss: 0.0014 - val_mae: 0.0309 - val_mse: 0.0014\n",
      "\n",
      "Epoch 5/25\n",
      "306/306 - 1s - loss: 0.0137 - mae: 0.0422 - mse: 0.0137 - val_loss: 0.0013 - val_mae: 0.0301 - val_mse: 0.0013\n",
      "\n",
      "Epoch 6/25\n",
      "306/306 - 1s - loss: 0.0138 - mae: 0.0423 - mse: 0.0138 - val_loss: 0.0013 - val_mae: 0.0295 - val_mse: 0.0013\n",
      "\n",
      "Epoch 7/25\n",
      "306/306 - 1s - loss: 0.0138 - mae: 0.0423 - mse: 0.0138 - val_loss: 0.0012 - val_mae: 0.0291 - val_mse: 0.0012\n",
      "\n",
      "Epoch 8/25\n",
      "306/306 - 1s - loss: 0.0138 - mae: 0.0422 - mse: 0.0138 - val_loss: 0.0012 - val_mae: 0.0287 - val_mse: 0.0012\n",
      "\n",
      "Epoch 9/25\n",
      "306/306 - 2s - loss: 0.0138 - mae: 0.0420 - mse: 0.0138 - val_loss: 0.0025 - val_mae: 0.0448 - val_mse: 0.0025\n",
      "\n",
      "Epoch 10/25\n",
      "306/306 - 1s - loss: 0.0126 - mae: 0.0400 - mse: 0.0126 - val_loss: 0.0012 - val_mae: 0.0285 - val_mse: 0.0012\n",
      "\n",
      "Epoch 11/25\n",
      "306/306 - 1s - loss: 0.0137 - mae: 0.0417 - mse: 0.0137 - val_loss: 0.0024 - val_mae: 0.0441 - val_mse: 0.0024\n",
      "\n",
      "Epoch 12/25\n",
      "306/306 - 1s - loss: 0.0126 - mae: 0.0398 - mse: 0.0126 - val_loss: 0.0012 - val_mae: 0.0286 - val_mse: 0.0012\n",
      "\n",
      "Epoch 13/25\n",
      "306/306 - 1s - loss: 0.0136 - mae: 0.0415 - mse: 0.0136 - val_loss: 0.0024 - val_mae: 0.0442 - val_mse: 0.0024\n",
      "\n",
      "Best Validation loss of epoch:\n",
      "0.0011923135025426745\n",
      "Epoch 1/25\n",
      "306/306 - 4s - loss: 0.0158 - mae: 0.0158 - mse: 5.9374e-04 - val_loss: 0.0402 - val_mae: 0.0402 - val_mse: 0.0021\n",
      "\n",
      "Epoch 2/25\n",
      "306/306 - 1s - loss: 0.0399 - mae: 0.0399 - mse: 0.0126 - val_loss: 0.0364 - val_mae: 0.0364 - val_mse: 0.0017\n",
      "\n",
      "Epoch 3/25\n",
      "306/306 - 1s - loss: 0.0418 - mae: 0.0418 - mse: 0.0138 - val_loss: 0.0346 - val_mae: 0.0346 - val_mse: 0.0015\n",
      "\n",
      "Epoch 4/25\n",
      "306/306 - 1s - loss: 0.0407 - mae: 0.0407 - mse: 0.0132 - val_loss: 0.0308 - val_mae: 0.0308 - val_mse: 0.0013\n",
      "\n",
      "Epoch 5/25\n",
      "306/306 - 1s - loss: 0.0406 - mae: 0.0406 - mse: 0.0130 - val_loss: 0.0301 - val_mae: 0.0301 - val_mse: 0.0012\n",
      "\n",
      "Epoch 6/25\n",
      "306/306 - 1s - loss: 0.0393 - mae: 0.0393 - mse: 0.0121 - val_loss: 0.0260 - val_mae: 0.0260 - val_mse: 9.2071e-04\n",
      "\n",
      "Epoch 7/25\n",
      "306/306 - 1s - loss: 0.0387 - mae: 0.0387 - mse: 0.0116 - val_loss: 0.0242 - val_mae: 0.0242 - val_mse: 8.0302e-04\n",
      "\n",
      "Epoch 8/25\n",
      "306/306 - 1s - loss: 0.0356 - mae: 0.0356 - mse: 0.0103 - val_loss: 0.0295 - val_mae: 0.0295 - val_mse: 0.0011\n",
      "\n",
      "Epoch 9/25\n",
      "306/306 - 1s - loss: 0.0315 - mae: 0.0315 - mse: 0.0082 - val_loss: 0.0212 - val_mae: 0.0212 - val_mse: 6.2218e-04\n",
      "\n",
      "Epoch 10/25\n",
      "306/306 - 1s - loss: 0.0315 - mae: 0.0315 - mse: 0.0080 - val_loss: 0.0277 - val_mae: 0.0277 - val_mse: 9.4033e-04\n",
      "\n",
      "Epoch 11/25\n",
      "306/306 - 1s - loss: 0.0248 - mae: 0.0248 - mse: 0.0053 - val_loss: 0.0269 - val_mae: 0.0269 - val_mse: 8.8039e-04\n",
      "\n",
      "Epoch 12/25\n",
      "306/306 - 1s - loss: 0.0238 - mae: 0.0238 - mse: 0.0049 - val_loss: 0.0197 - val_mae: 0.0197 - val_mse: 5.2241e-04\n",
      "\n",
      "Epoch 13/25\n",
      "306/306 - 1s - loss: 0.0225 - mae: 0.0225 - mse: 0.0043 - val_loss: 0.0175 - val_mae: 0.0175 - val_mse: 4.1833e-04\n",
      "\n",
      "Epoch 14/25\n",
      "306/306 - 1s - loss: 0.0195 - mae: 0.0195 - mse: 0.0034 - val_loss: 0.0166 - val_mae: 0.0166 - val_mse: 3.7155e-04\n",
      "\n",
      "Epoch 15/25\n",
      "306/306 - 1s - loss: 0.0173 - mae: 0.0173 - mse: 0.0025 - val_loss: 0.0149 - val_mae: 0.0149 - val_mse: 3.0225e-04\n",
      "\n",
      "Epoch 16/25\n",
      "306/306 - 1s - loss: 0.0157 - mae: 0.0157 - mse: 0.0020 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 1.9883e-04\n",
      "\n",
      "Epoch 17/25\n",
      "306/306 - 1s - loss: 0.0139 - mae: 0.0139 - mse: 0.0016 - val_loss: 0.0188 - val_mae: 0.0188 - val_mse: 4.2265e-04\n",
      "\n",
      "Epoch 18/25\n",
      "306/306 - 1s - loss: 0.0121 - mae: 0.0121 - mse: 0.0011 - val_loss: 0.0095 - val_mae: 0.0095 - val_mse: 1.3042e-04\n",
      "\n",
      "Epoch 19/25\n",
      "306/306 - 1s - loss: 0.0108 - mae: 0.0108 - mse: 7.8893e-04 - val_loss: 0.0090 - val_mae: 0.0090 - val_mse: 1.1506e-04\n",
      "\n",
      "Epoch 20/25\n",
      "306/306 - 1s - loss: 0.0090 - mae: 0.0090 - mse: 5.2336e-04 - val_loss: 0.0084 - val_mae: 0.0084 - val_mse: 1.0115e-04\n",
      "\n",
      "Epoch 21/25\n",
      "306/306 - 1s - loss: 0.0081 - mae: 0.0081 - mse: 3.9781e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 1.9931e-04\n",
      "\n",
      "Epoch 22/25\n",
      "306/306 - 1s - loss: 0.0076 - mae: 0.0076 - mse: 3.0587e-04 - val_loss: 0.0074 - val_mae: 0.0074 - val_mse: 8.0407e-05\n",
      "\n",
      "Epoch 23/25\n",
      "306/306 - 1s - loss: 0.0075 - mae: 0.0075 - mse: 2.8904e-04 - val_loss: 0.0060 - val_mae: 0.0060 - val_mse: 5.3869e-05\n",
      "\n",
      "Epoch 24/25\n",
      "306/306 - 1s - loss: 0.0068 - mae: 0.0068 - mse: 2.1441e-04 - val_loss: 0.0057 - val_mae: 0.0057 - val_mse: 5.0367e-05\n",
      "\n",
      "Epoch 25/25\n",
      "306/306 - 1s - loss: 0.0056 - mae: 0.0056 - mse: 1.0404e-04 - val_loss: 0.0093 - val_mae: 0.0093 - val_mse: 1.1045e-04\n",
      "\n",
      "Best Validation loss of epoch:\n",
      "0.0057363370433449745\n",
      "Epoch 1/25\n",
      "306/306 - 2s - loss: 0.0173 - mae: 0.0173 - mse: 4.5436e-04 - val_loss: 0.0572 - val_mae: 0.0572 - val_mse: 0.0040\n",
      "\n",
      "Epoch 2/25\n",
      "306/306 - 1s - loss: 0.0359 - mae: 0.0359 - mse: 0.0093 - val_loss: 0.0250 - val_mae: 0.0250 - val_mse: 9.4363e-04\n",
      "\n",
      "Epoch 3/25\n",
      "306/306 - 1s - loss: 0.0372 - mae: 0.0372 - mse: 0.0106 - val_loss: 0.0318 - val_mae: 0.0318 - val_mse: 0.0015\n",
      "\n",
      "Epoch 4/25\n",
      "306/306 - 1s - loss: 0.0364 - mae: 0.0364 - mse: 0.0100 - val_loss: 0.0278 - val_mae: 0.0278 - val_mse: 0.0012\n",
      "\n",
      "Epoch 5/25\n",
      "306/306 - 1s - loss: 0.0365 - mae: 0.0365 - mse: 0.0101 - val_loss: 0.0263 - val_mae: 0.0263 - val_mse: 0.0010\n",
      "\n",
      "Best Validation loss of epoch:\n",
      "0.02500353939831257\n",
      "Epoch 1/25\n",
      "306/306 - 2s - loss: 0.0014 - mae: 0.0322 - mse: 0.0014 - val_loss: 0.0053 - val_mae: 0.0651 - val_mse: 0.0053\n",
      "\n",
      "Epoch 2/25\n",
      "306/306 - 1s - loss: 0.0093 - mae: 0.0499 - mse: 0.0093 - val_loss: 0.0050 - val_mae: 0.0641 - val_mse: 0.0050\n",
      "\n",
      "Epoch 3/25\n",
      "306/306 - 1s - loss: 0.0090 - mae: 0.0489 - mse: 0.0090 - val_loss: 0.0048 - val_mae: 0.0633 - val_mse: 0.0048\n",
      "\n",
      "Epoch 4/25\n",
      "306/306 - 1s - loss: 0.0086 - mae: 0.0480 - mse: 0.0086 - val_loss: 0.0047 - val_mae: 0.0624 - val_mse: 0.0047\n",
      "\n",
      "Epoch 5/25\n",
      "306/306 - 1s - loss: 0.0083 - mae: 0.0471 - mse: 0.0083 - val_loss: 0.0045 - val_mae: 0.0616 - val_mse: 0.0045\n",
      "\n",
      "Epoch 6/25\n",
      "306/306 - 1s - loss: 0.0080 - mae: 0.0461 - mse: 0.0080 - val_loss: 0.0044 - val_mae: 0.0607 - val_mse: 0.0044\n",
      "\n",
      "Epoch 7/25\n",
      "306/306 - 1s - loss: 0.0077 - mae: 0.0451 - mse: 0.0077 - val_loss: 0.0042 - val_mae: 0.0598 - val_mse: 0.0042\n",
      "\n",
      "Epoch 8/25\n",
      "306/306 - 1s - loss: 0.0074 - mae: 0.0442 - mse: 0.0074 - val_loss: 0.0041 - val_mae: 0.0589 - val_mse: 0.0041\n",
      "\n",
      "Epoch 9/25\n",
      "306/306 - 1s - loss: 0.0072 - mae: 0.0432 - mse: 0.0072 - val_loss: 0.0039 - val_mae: 0.0579 - val_mse: 0.0039\n",
      "\n",
      "Epoch 10/25\n",
      "306/306 - 1s - loss: 0.0069 - mae: 0.0422 - mse: 0.0069 - val_loss: 0.0038 - val_mae: 0.0569 - val_mse: 0.0038\n",
      "\n",
      "Epoch 11/25\n",
      "306/306 - 1s - loss: 0.0066 - mae: 0.0412 - mse: 0.0066 - val_loss: 0.0037 - val_mae: 0.0559 - val_mse: 0.0037\n",
      "\n",
      "Epoch 12/25\n",
      "306/306 - 1s - loss: 0.0063 - mae: 0.0402 - mse: 0.0063 - val_loss: 0.0035 - val_mae: 0.0549 - val_mse: 0.0035\n",
      "\n",
      "Epoch 13/25\n",
      "306/306 - 1s - loss: 0.0061 - mae: 0.0392 - mse: 0.0061 - val_loss: 0.0034 - val_mae: 0.0539 - val_mse: 0.0034\n",
      "\n",
      "Epoch 14/25\n",
      "306/306 - 1s - loss: 0.0058 - mae: 0.0382 - mse: 0.0058 - val_loss: 0.0033 - val_mae: 0.0529 - val_mse: 0.0033\n",
      "\n",
      "Epoch 15/25\n",
      "306/306 - 1s - loss: 0.0056 - mae: 0.0371 - mse: 0.0056 - val_loss: 0.0032 - val_mae: 0.0518 - val_mse: 0.0032\n",
      "\n",
      "Epoch 16/25\n",
      "306/306 - 1s - loss: 0.0053 - mae: 0.0361 - mse: 0.0053 - val_loss: 0.0031 - val_mae: 0.0508 - val_mse: 0.0031\n",
      "\n",
      "Epoch 17/25\n",
      "306/306 - 1s - loss: 0.0051 - mae: 0.0351 - mse: 0.0051 - val_loss: 0.0029 - val_mae: 0.0497 - val_mse: 0.0029\n",
      "\n",
      "Epoch 18/25\n",
      "306/306 - 1s - loss: 0.0048 - mae: 0.0341 - mse: 0.0048 - val_loss: 0.0028 - val_mae: 0.0487 - val_mse: 0.0028\n",
      "\n",
      "Epoch 19/25\n",
      "306/306 - 1s - loss: 0.0046 - mae: 0.0331 - mse: 0.0046 - val_loss: 0.0027 - val_mae: 0.0476 - val_mse: 0.0027\n",
      "\n",
      "Epoch 20/25\n",
      "306/306 - 1s - loss: 0.0044 - mae: 0.0322 - mse: 0.0044 - val_loss: 0.0026 - val_mae: 0.0466 - val_mse: 0.0026\n",
      "\n",
      "Epoch 21/25\n",
      "306/306 - 1s - loss: 0.0041 - mae: 0.0312 - mse: 0.0041 - val_loss: 0.0025 - val_mae: 0.0455 - val_mse: 0.0025\n",
      "\n",
      "Epoch 22/25\n",
      "306/306 - 1s - loss: 0.0039 - mae: 0.0303 - mse: 0.0039 - val_loss: 0.0024 - val_mae: 0.0445 - val_mse: 0.0024\n",
      "\n",
      "Epoch 23/25\n",
      "306/306 - 1s - loss: 0.0037 - mae: 0.0293 - mse: 0.0037 - val_loss: 0.0023 - val_mae: 0.0434 - val_mse: 0.0023\n",
      "\n",
      "Epoch 24/25\n",
      "306/306 - 1s - loss: 0.0035 - mae: 0.0284 - mse: 0.0035 - val_loss: 0.0022 - val_mae: 0.0424 - val_mse: 0.0022\n",
      "\n",
      "Epoch 25/25\n",
      "306/306 - 1s - loss: 0.0033 - mae: 0.0276 - mse: 0.0033 - val_loss: 0.0021 - val_mae: 0.0414 - val_mse: 0.0021\n",
      "\n",
      "Best Validation loss of epoch:\n",
      "0.002091206144541502\n",
      "Epoch 1/25\n",
      "306/306 - 1s - loss: 2.6590e-04 - mae: 0.0122 - mse: 2.6590e-04 - val_loss: 0.0026 - val_mae: 0.0457 - val_mse: 0.0026\n",
      "\n",
      "Epoch 2/25\n",
      "306/306 - 1s - loss: 0.0042 - mae: 0.0233 - mse: 0.0042 - val_loss: 0.0018 - val_mae: 0.0375 - val_mse: 0.0018\n",
      "\n",
      "Epoch 3/25\n",
      "306/306 - 1s - loss: 0.0043 - mae: 0.0245 - mse: 0.0043 - val_loss: 0.0016 - val_mae: 0.0354 - val_mse: 0.0016\n",
      "\n",
      "Epoch 4/25\n",
      "306/306 - 1s - loss: 0.0043 - mae: 0.0244 - mse: 0.0043 - val_loss: 0.0017 - val_mae: 0.0362 - val_mse: 0.0017\n",
      "\n",
      "Epoch 5/25\n",
      "306/306 - 1s - loss: 0.0043 - mae: 0.0257 - mse: 0.0043 - val_loss: 0.0012 - val_mae: 0.0303 - val_mse: 0.0012\n",
      "\n",
      "Epoch 6/25\n",
      "306/306 - 1s - loss: 0.0039 - mae: 0.0260 - mse: 0.0039 - val_loss: 0.0014 - val_mae: 0.0342 - val_mse: 0.0014\n",
      "\n",
      "Epoch 7/25\n",
      "306/306 - 1s - loss: 0.0039 - mae: 0.0275 - mse: 0.0039 - val_loss: 9.0037e-04 - val_mae: 0.0263 - val_mse: 9.0037e-04\n",
      "\n",
      "Epoch 8/25\n",
      "306/306 - 1s - loss: 0.0040 - mae: 0.0295 - mse: 0.0040 - val_loss: 6.5190e-04 - val_mae: 0.0222 - val_mse: 6.5190e-04\n",
      "\n",
      "Epoch 9/25\n",
      "306/306 - 1s - loss: 0.0036 - mae: 0.0285 - mse: 0.0036 - val_loss: 6.0296e-04 - val_mae: 0.0213 - val_mse: 6.0296e-04\n",
      "\n",
      "Epoch 10/25\n",
      "306/306 - 1s - loss: 0.0033 - mae: 0.0281 - mse: 0.0033 - val_loss: 5.0628e-04 - val_mae: 0.0193 - val_mse: 5.0628e-04\n",
      "\n",
      "Epoch 11/25\n",
      "306/306 - 1s - loss: 0.0026 - mae: 0.0261 - mse: 0.0026 - val_loss: 3.8471e-04 - val_mae: 0.0164 - val_mse: 3.8471e-04\n",
      "\n",
      "Epoch 12/25\n",
      "306/306 - 1s - loss: 0.0018 - mae: 0.0193 - mse: 0.0018 - val_loss: 2.3502e-04 - val_mae: 0.0127 - val_mse: 2.3502e-04\n",
      "\n",
      "Epoch 13/25\n",
      "306/306 - 1s - loss: 9.9450e-04 - mae: 0.0135 - mse: 9.9450e-04 - val_loss: 1.2575e-04 - val_mae: 0.0092 - val_mse: 1.2575e-04\n",
      "\n",
      "Epoch 14/25\n",
      "306/306 - 1s - loss: 4.4684e-04 - mae: 0.0097 - mse: 4.4684e-04 - val_loss: 6.2132e-05 - val_mae: 0.0065 - val_mse: 6.2132e-05\n",
      "\n",
      "Epoch 15/25\n",
      "306/306 - 1s - loss: 1.6842e-04 - mae: 0.0071 - mse: 1.6842e-04 - val_loss: 3.8705e-05 - val_mae: 0.0051 - val_mse: 3.8705e-05\n",
      "\n",
      "Epoch 16/25\n",
      "306/306 - 1s - loss: 7.0907e-05 - mae: 0.0054 - mse: 7.0907e-05 - val_loss: 3.0814e-05 - val_mae: 0.0045 - val_mse: 3.0814e-05\n",
      "\n",
      "Epoch 17/25\n",
      "306/306 - 1s - loss: 4.3755e-05 - mae: 0.0045 - mse: 4.3755e-05 - val_loss: 2.9464e-05 - val_mae: 0.0045 - val_mse: 2.9464e-05\n",
      "\n",
      "Epoch 18/25\n",
      "306/306 - 1s - loss: 3.3403e-05 - mae: 0.0039 - mse: 3.3403e-05 - val_loss: 3.5443e-05 - val_mae: 0.0049 - val_mse: 3.5443e-05\n",
      "\n",
      "Epoch 19/25\n",
      "306/306 - 1s - loss: 2.6828e-05 - mae: 0.0034 - mse: 2.6828e-05 - val_loss: 3.7645e-05 - val_mae: 0.0050 - val_mse: 3.7645e-05\n",
      "\n",
      "Epoch 20/25\n",
      "306/306 - 1s - loss: 2.1854e-05 - mae: 0.0030 - mse: 2.1854e-05 - val_loss: 3.4459e-05 - val_mae: 0.0048 - val_mse: 3.4459e-05\n",
      "\n",
      "Best Validation loss of epoch:\n",
      "2.9464043109328486e-05\n",
      "100%|██████████| 5/5 [01:49<00:00, 21.86s/trial, best loss: 2.9464043109328486e-05]\n",
      "Evaluation of best performing model:\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0443 - mse: 0.0024\n",
      "[0.0024317344650626183, 0.0443362295627594, 0.0024317344650626183]\n",
      "Best Performing Model Hyper-Parameters:\n",
      "{'Dense': 2, 'LSTM': 3, 'loss': 1, 'optimizer': 0}\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "from hyperas import optim\n",
    "from hyperopt import Trials, tpe\n",
    "\n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                        data=data,\n",
    "                                        algo=tpe.suggest,\n",
    "                                        max_evals=5,\n",
    "                                        trials=Trials(),\n",
    "                                        notebook_name = 'HyperParameter_Tuning')\n",
    "                                        \n",
    "X_train, y_train, X_test, y_test = data()\n",
    "print('Evaluation of best performing model:')\n",
    "print(best_model.evaluate(X_test, y_test))\n",
    "print(\"Best Performing Model Hyper-Parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    from hyperas import optim\n",
    "    from hyperopt import Trials, tpe\n",
    "\n",
    "    best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name = 'BlackBox')\n",
    "                                          \n",
    "    X_train, y_train, X_test, y_test = data()\n",
    "    print('Evaluation of best performing model:')\n",
    "    print(best_model.evaluate(X_test, y_test))\n",
    "    print(\"Best Performing Model Hyper-Parameters:\")\n",
    "    print(best_run)"
   ]
  }
 ]
}