{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('WeatherML': conda)",
   "display_name": "Python 3.8.5 64-bit ('WeatherML': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fa0a90ea388e647b6806305426e0b9939b78a8fc99087e1c6cd6e6ae226ce148"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from matplotlib import pyplot as plt\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.layers import LSTM\n",
    "# from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "\n",
    "# from hyperas import optim\n",
    "# from hyperas.distributions import choice, uniform\n",
    "# from hyperopt import Trials, STATUS_OK, tpe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"model_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    df = pd.read_csv(\"model_data.csv\")\n",
    "\n",
    "    def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "        n_vars = 1 if type(data) is list else data.shape[1]\n",
    "        df = pd.DataFrame(data)\n",
    "        cols, names = list(), list()\n",
    "        # input sequence (t-n, ... t-1)\n",
    "        for i in range(n_in, 0, -1):\n",
    "            cols.append(df.shift(i))\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "        # forecast sequence (t, t+1, ... t+n)\n",
    "        for i in range(0, n_out):\n",
    "            cols.append(df.shift(-i))\n",
    "            if i == 0:\n",
    "                names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "            else:\n",
    "                names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "        # put it all together\n",
    "        agg = pd.concat(cols, axis=1)\n",
    "        agg.columns = names\n",
    "        # drop rows with NaN values\n",
    "        if dropnan:\n",
    "            agg.dropna(inplace=True)\n",
    "        return agg\n",
    "\n",
    "    values = df.drop([\"Date\"], axis=1).values\n",
    "    values = values.astype(\"float32\")\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(values)\n",
    "\n",
    "    reframed = series_to_supervised(scaled, 1, 1)\n",
    "    reframed.drop(reframed.columns[[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    reframe_values = reframed.values\n",
    "    X = reframe_values[:,:-1]\n",
    "    y = reframe_values[:, -1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False)\n",
    "    X_train = np.expand_dims(X_train, axis=1)\n",
    "    X_test = np.expand_dims(X_test, axis=1)\n",
    "    y_train = np.expand_dims(y_train, axis=1)\n",
    "    y_test = np.expand_dims(y_test, axis=1)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(20354, 1, 15)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6785, 1, 15)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(20354, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, X_test, y_train, y_test):\n",
    "\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.layers import Dense\n",
    "        from tensorflow.keras.layers import LSTM\n",
    "        from hyperas.distributions import choice, uniform\n",
    "        from hyperopt import STATUS_OK\n",
    "\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM({{choice([10, 25, 50, 75, 100])}}, \n",
    "                input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "                )\n",
    "\n",
    "        model.add(Dense({{choice([10, 20, 50, 100])}}))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss={{choice([\"mae\", 'categorical_crossentropy'])}}, \n",
    "                    optimizer={{choice([\"adam\", \"sgd\", \"rmsprop\"])}}, \n",
    "                    metrics=[\"mse\"])\n",
    "\n",
    "        result = model.fit(X_train, y_train, epochs=25, batch_size=60, validation_split=0.1, verbose=2, shuffle=False)\n",
    "\n",
    "        print(result.history)\n",
    "\n",
    "        validation_acc=np.amax(result.history['loss'])\n",
    "        print('Best Validation acc of epoch:', validation_acc)\n",
    "        return {'loss': -validation_acc, 'status': STATUS_OK, 'model':model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from matplotlib import pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import LabelEncoder\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import MinMaxScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import mean_squared_error\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import LSTM\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'LSTM': hp.choice('LSTM', [10, 25, 50, 75, 100]),\n",
      "        'Dense': hp.choice('Dense', [10, 20, 50, 100]),\n",
      "        'loss': hp.choice('loss', [\"mae\", 'categorical_crossentropy']),\n",
      "        'optimizer': hp.choice('optimizer', [\"adam\", \"sgd\", \"rmsprop\"]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: import pandas as pd\n",
      "   3: import numpy as np\n",
      "   4: from sklearn.preprocessing import MinMaxScaler\n",
      "   5: from sklearn.model_selection import train_test_split\n",
      "   6: \n",
      "   7: df = pd.read_csv(\"model_data.csv\")\n",
      "   8: \n",
      "   9: def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
      "  10:     n_vars = 1 if type(data) is list else data.shape[1]\n",
      "  11:     df = pd.DataFrame(data)\n",
      "  12:     cols, names = list(), list()\n",
      "  13:     # input sequence (t-n, ... t-1)\n",
      "  14:     for i in range(n_in, 0, -1):\n",
      "  15:         cols.append(df.shift(i))\n",
      "  16:         names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
      "  17:     # forecast sequence (t, t+1, ... t+n)\n",
      "  18:     for i in range(0, n_out):\n",
      "  19:         cols.append(df.shift(-i))\n",
      "  20:         if i == 0:\n",
      "  21:             names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
      "  22:         else:\n",
      "  23:             names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
      "  24:     # put it all together\n",
      "  25:     agg = pd.concat(cols, axis=1)\n",
      "  26:     agg.columns = names\n",
      "  27:     # drop rows with NaN values\n",
      "  28:     if dropnan:\n",
      "  29:         agg.dropna(inplace=True)\n",
      "  30:     return agg\n",
      "  31: \n",
      "  32: values = df.drop([\"Date\"], axis=1).values\n",
      "  33: values = values.astype(\"float32\")\n",
      "  34: scaler = MinMaxScaler(feature_range=(0, 1))\n",
      "  35: scaled = scaler.fit_transform(values)\n",
      "  36: \n",
      "  37: reframed = series_to_supervised(scaled, 1, 1)\n",
      "  38: reframed.drop(reframed.columns[[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]], axis=1, inplace=True)\n",
      "  39: \n",
      "  40: \n",
      "  41: reframe_values = reframed.values\n",
      "  42: X = reframe_values[:,:-1]\n",
      "  43: y = reframe_values[:, -1]\n",
      "  44: \n",
      "  45: X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False)\n",
      "  46: X_train = np.expand_dims(X_train, axis=1)\n",
      "  47: X_test = np.expand_dims(X_test, axis=1)\n",
      "  48: y_train = np.expand_dims(y_train, axis=1)\n",
      "  49: y_test = np.expand_dims(y_test, axis=1)\n",
      "  50: \n",
      "  51: \n",
      "  52: \n",
      "  53: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "  1: def keras_fmin_fnct(space):\n",
      "  2: \n",
      "  3: \n",
      "  4: \n",
      "  5: \n",
      "  6:         model = Sequential()\n",
      "  7:         model.add(LSTM(space['LSTM'], \n",
      "  8:                 input_shape=(X_train.shape[1], X_train.shape[2]))\n",
      "  9:                 )\n",
      " 10: \n",
      " 11:         model.add(Dense(space['Dense']))\n",
      " 12:         model.add(Dense(1))\n",
      " 13:         model.compile(loss=space['loss'], \n",
      " 14:                     optimizer=space['optimizer'], \n",
      " 15:                     metrics=[\"mse\"])\n",
      " 16: \n",
      " 17:         result = model.fit(X_train, y_train, epochs=25, batch_size=60, validation_split=0.1, verbose=2, shuffle=False)\n",
      " 18: \n",
      " 19:         print(result.history)\n",
      " 20: \n",
      " 21:         validation_acc=np.amax(result.history['val_accuracy'])\n",
      " 22:         print('Best Validation acc of epoch:', validation_acc)\n",
      " 23:         return {'loss': -validation_acc, 'status': STATUS_OK, 'model':model}\n",
      " 24: \n",
      "Epoch 1/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 2/25\n",
      "306/306 - 0s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 3/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 4/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 5/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 6/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 7/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 8/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 9/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 10/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 11/25\n",
      "306/306 - 0s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 12/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 13/25\n",
      "306/306 - 0s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 14/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 15/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 16/25\n",
      "306/306 - 0s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 17/25\n",
      "306/306 - 0s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 18/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 19/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 20/25\n",
      "306/306 - 0s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 21/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 22/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 23/25\n",
      "306/306 - 0s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 24/25\n",
      "306/306 - 0s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "Epoch 25/25\n",
      "306/306 - 1s - loss: 4.0234e-08 - mse: 0.1334 - val_loss: 8.4936e-08 - val_mse: 0.4497\n",
      "\n",
      "{'loss': [4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08, 4.023351252158136e-08], 'mse': [0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512, 0.1333850473165512], 'val_loss': [8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08, 8.493644543250412e-08], 'val_mse': [0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884, 0.4496769309043884]}\n",
      "  0%|          | 0/5 [00:16<?, ?trial/s, best loss=?]job exception: 'val_accuracy'\n",
      "\n",
      "  0%|          | 0/5 [00:16<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5e00ec04a0f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     best_run, best_model = optim.minimize(model=create_model,\n\u001b[0m\u001b[1;32m      6\u001b[0m                                           \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                           \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/WeatherML/lib/python3.8/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mreturn_space\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpair\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0msearch\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \"\"\"\n\u001b[0;32m---> 59\u001b[0;31m     best_run, space = base_minimizer(model=model,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                      \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                                      \u001b[0mfunctions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/WeatherML/lib/python3.8/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     return (\n\u001b[0;32m--> 133\u001b[0;31m         fmin(keras_fmin_fnct,\n\u001b[0m\u001b[1;32m    134\u001b[0m              \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m              \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/WeatherML/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/WeatherML/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    683\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/WeatherML/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/WeatherML/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/WeatherML/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/WeatherML/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/WeatherML/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    905\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             )\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Rice/Projects/Project_3/Project03_Team01/temp_model.py\u001b[0m in \u001b[0;36mkeras_fmin_fnct\u001b[0;34m(space)\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from hyperas import optim\n",
    "    from hyperopt import Trials, tpe\n",
    "\n",
    "    best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name = 'BlackBox')\n",
    "                                          \n",
    "    X_train, y_train, X_test, y_test = data()\n",
    "    print('Evaluation of best performing model:')\n",
    "    print(best_model.evaluate(X_test, y_test))\n",
    "    print(\"Best Performing Model Hyper-Parameters:\")\n",
    "    print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}