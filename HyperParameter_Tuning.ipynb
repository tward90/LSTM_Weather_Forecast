{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('WeatherML': conda)",
   "display_name": "Python 3.8.5 64-bit ('WeatherML': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fa0a90ea388e647b6806305426e0b9939b78a8fc99087e1c6cd6e6ae226ce148"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from matplotlib import pyplot as plt\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.layers import LSTM\n",
    "# from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "\n",
    "# from hyperas import optim\n",
    "# from hyperas.distributions import choice, uniform\n",
    "# from hyperopt import Trials, STATUS_OK, tpe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"model_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    df = pd.read_csv(\"model_data.csv\")\n",
    "\n",
    "    def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "        n_vars = 1 if type(data) is list else data.shape[1]\n",
    "        df = pd.DataFrame(data)\n",
    "        cols, names = list(), list()\n",
    "        # input sequence (t-n, ... t-1)\n",
    "        for i in range(n_in, 0, -1):\n",
    "            cols.append(df.shift(i))\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "        # forecast sequence (t, t+1, ... t+n)\n",
    "        for i in range(0, n_out):\n",
    "            cols.append(df.shift(-i))\n",
    "            if i == 0:\n",
    "                names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "            else:\n",
    "                names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "        # put it all together\n",
    "        agg = pd.concat(cols, axis=1)\n",
    "        agg.columns = names\n",
    "        # drop rows with NaN values\n",
    "        if dropnan:\n",
    "            agg.dropna(inplace=True)\n",
    "        return agg\n",
    "\n",
    "    values = df.drop([\"Date\"], axis=1).values\n",
    "    values = values.astype(\"float32\")\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(values)\n",
    "\n",
    "    reframed = series_to_supervised(scaled, 1, 1)\n",
    "    reframed.drop(reframed.columns[[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    reframe_values = reframed.values\n",
    "    X = reframe_values[:,:-1]\n",
    "    y = reframe_values[:, -1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False)\n",
    "    X_train = np.expand_dims(X_train, axis=1)\n",
    "    X_test = np.expand_dims(X_test, axis=1)\n",
    "    y_train = np.expand_dims(y_train, axis=1)\n",
    "    y_test = np.expand_dims(y_test, axis=1)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(20354, 1, 15)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6785, 1, 15)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "import numpy as numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, X_test, y_train, y_test):\n",
    "\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.layers import Dense\n",
    "        from tensorflow.keras.layers import LSTM\n",
    "        from hyperas.distributions import choice, uniform\n",
    "        from hyperopt import STATUS_OK\n",
    "\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM({{choice([5, 10, 25, 50, 75, 100])}}, \n",
    "                input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "                )\n",
    "\n",
    "        model.add(Dense({{choice([10, 20, 50, 100])}}))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss={{choice([\"mae\", \"mse\"])}}, \n",
    "                    optimizer={{choice([\"adam\", \"sgd\", \"rmsprop\"])}}, \n",
    "                    metrics=[\"mae\", \"mse\"]\n",
    "                    )\n",
    "        e_stop =  tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n",
    "\n",
    "        result = model.fit(X_train, y_train, epochs=25, batch_size=60, validation_split=0.1, verbose=2, callbacks = [e_stop], shuffle=False)\n",
    "\n",
    "        # print(result.history)\n",
    "\n",
    "        validation_loss = np.amin(result.history['val_loss'])\n",
    "        print('Best Validation loss of epoch:', validation_loss)\n",
    "        return {'loss': validation_loss, 'status': STATUS_OK, 'model':model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from matplotlib import pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import LabelEncoder\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import MinMaxScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import mean_squared_error\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import LSTM\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'LSTM': hp.choice('LSTM', [5, 10, 25, 50, 75, 100]),\n",
      "        'Dense': hp.choice('Dense', [10, 20, 50, 100]),\n",
      "        'loss': hp.choice('loss', [\"mae\", \"mse\"]),\n",
      "        'optimizer': hp.choice('optimizer', [\"adam\", \"sgd\", \"rmsprop\"]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: import pandas as pd\n",
      "   3: import numpy as np\n",
      "   4: from sklearn.preprocessing import MinMaxScaler\n",
      "   5: from sklearn.model_selection import train_test_split\n",
      "   6: \n",
      "   7: df = pd.read_csv(\"model_data.csv\")\n",
      "   8: \n",
      "   9: def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
      "  10:     n_vars = 1 if type(data) is list else data.shape[1]\n",
      "  11:     df = pd.DataFrame(data)\n",
      "  12:     cols, names = list(), list()\n",
      "  13:     # input sequence (t-n, ... t-1)\n",
      "  14:     for i in range(n_in, 0, -1):\n",
      "  15:         cols.append(df.shift(i))\n",
      "  16:         names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
      "  17:     # forecast sequence (t, t+1, ... t+n)\n",
      "  18:     for i in range(0, n_out):\n",
      "  19:         cols.append(df.shift(-i))\n",
      "  20:         if i == 0:\n",
      "  21:             names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
      "  22:         else:\n",
      "  23:             names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
      "  24:     # put it all together\n",
      "  25:     agg = pd.concat(cols, axis=1)\n",
      "  26:     agg.columns = names\n",
      "  27:     # drop rows with NaN values\n",
      "  28:     if dropnan:\n",
      "  29:         agg.dropna(inplace=True)\n",
      "  30:     return agg\n",
      "  31: \n",
      "  32: values = df.drop([\"Date\"], axis=1).values\n",
      "  33: values = values.astype(\"float32\")\n",
      "  34: scaler = MinMaxScaler(feature_range=(0, 1))\n",
      "  35: scaled = scaler.fit_transform(values)\n",
      "  36: \n",
      "  37: reframed = series_to_supervised(scaled, 1, 1)\n",
      "  38: reframed.drop(reframed.columns[[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]], axis=1, inplace=True)\n",
      "  39: \n",
      "  40: \n",
      "  41: reframe_values = reframed.values\n",
      "  42: X = reframe_values[:,:-1]\n",
      "  43: y = reframe_values[:, -1]\n",
      "  44: \n",
      "  45: X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False)\n",
      "  46: X_train = np.expand_dims(X_train, axis=1)\n",
      "  47: X_test = np.expand_dims(X_test, axis=1)\n",
      "  48: y_train = np.expand_dims(y_train, axis=1)\n",
      "  49: y_test = np.expand_dims(y_test, axis=1)\n",
      "  50: \n",
      "  51: \n",
      "  52: \n",
      "  53: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "  1: def keras_fmin_fnct(space):\n",
      "  2: \n",
      "  3: \n",
      "  4: \n",
      "  5: \n",
      "  6:         model = Sequential()\n",
      "  7:         model.add(LSTM(space['LSTM'], \n",
      "  8:                 input_shape=(X_train.shape[1], X_train.shape[2]))\n",
      "  9:                 )\n",
      " 10: \n",
      " 11:         model.add(Dense(space['Dense']))\n",
      " 12:         model.add(Dense(1))\n",
      " 13:         model.compile(loss=space['loss'], \n",
      " 14:                     optimizer=space['optimizer'], \n",
      " 15:                     metrics=[\"mae\", \"mse\"]\n",
      " 16:                     )\n",
      " 17:         e_stop =  tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n",
      " 18: \n",
      " 19:         result = model.fit(X_train, y_train, epochs=25, batch_size=60, validation_split=0.1, verbose=2, callbacks = [e_stop], shuffle=False)\n",
      " 20: \n",
      " 21:         # print(result.history)\n",
      " 22: \n",
      " 23:         validation_loss = np.amin(result.history['val_loss'])\n",
      " 24:         print('Best Validation loss of epoch:', validation_loss)\n",
      " 25:         return {'loss': validation_loss, 'status': STATUS_OK, 'model':model}\n",
      " 26: \n",
      "Epoch 1/25\n",
      "306/306 - 1s - loss: 1.3493e-04 - mae: 0.0093 - mse: 1.3493e-04 - val_loss: 0.0043 - val_mae: 0.0613 - val_mse: 0.0043\n",
      "\n",
      "Epoch 2/25\n",
      "306/306 - 1s - loss: 0.0114 - mae: 0.0406 - mse: 0.0114 - val_loss: 0.0035 - val_mae: 0.0553 - val_mse: 0.0035\n",
      "\n",
      "Epoch 3/25\n",
      "306/306 - 1s - loss: 0.0109 - mae: 0.0388 - mse: 0.0109 - val_loss: 0.0032 - val_mae: 0.0517 - val_mse: 0.0032\n",
      "\n",
      "Epoch 4/25\n",
      "306/306 - 1s - loss: 0.0104 - mae: 0.0372 - mse: 0.0104 - val_loss: 0.0027 - val_mae: 0.0472 - val_mse: 0.0027\n",
      "\n",
      "Epoch 5/25\n",
      "306/306 - 1s - loss: 0.0102 - mae: 0.0371 - mse: 0.0102 - val_loss: 0.0017 - val_mae: 0.0351 - val_mse: 0.0017\n",
      "\n",
      "Epoch 6/25\n",
      "306/306 - 1s - loss: 0.0102 - mae: 0.0377 - mse: 0.0102 - val_loss: 0.0036 - val_mae: 0.0553 - val_mse: 0.0036\n",
      "\n",
      "Epoch 7/25\n",
      "306/306 - 1s - loss: 0.0086 - mae: 0.0348 - mse: 0.0086 - val_loss: 0.0033 - val_mae: 0.0533 - val_mse: 0.0033\n",
      "\n",
      "Epoch 8/25\n",
      "306/306 - 1s - loss: 0.0085 - mae: 0.0341 - mse: 0.0085 - val_loss: 0.0031 - val_mae: 0.0511 - val_mse: 0.0031\n",
      "\n",
      "Best Validation loss of epoch:\n",
      "0.001694856327958405\n",
      "Epoch 1/25\n",
      "306/306 - 1s - loss: 0.0149 - mae: 0.0149 - mse: 5.2075e-04 - val_loss: 0.0352 - val_mae: 0.0352 - val_mse: 0.0016\n",
      "\n",
      "Epoch 2/25\n",
      "306/306 - 1s - loss: 0.0396 - mae: 0.0396 - mse: 0.0123 - val_loss: 0.0340 - val_mae: 0.0340 - val_mse: 0.0015\n",
      "\n",
      "Epoch 3/25\n",
      "306/306 - 1s - loss: 0.0426 - mae: 0.0426 - mse: 0.0142 - val_loss: 0.0271 - val_mae: 0.0271 - val_mse: 0.0010\n",
      "\n",
      "Epoch 4/25\n",
      "306/306 - 1s - loss: 0.0441 - mae: 0.0441 - mse: 0.0148 - val_loss: 0.0272 - val_mae: 0.0272 - val_mse: 0.0010\n",
      "\n",
      "Epoch 5/25\n",
      "306/306 - 1s - loss: 0.0397 - mae: 0.0397 - mse: 0.0120 - val_loss: 0.0258 - val_mae: 0.0258 - val_mse: 9.1888e-04\n",
      "\n",
      "Epoch 6/25\n",
      "306/306 - 1s - loss: 0.0404 - mae: 0.0404 - mse: 0.0125 - val_loss: 0.0233 - val_mae: 0.0233 - val_mse: 7.6489e-04\n",
      "\n",
      "Epoch 7/25\n",
      "306/306 - 1s - loss: 0.0398 - mae: 0.0398 - mse: 0.0120 - val_loss: 0.0220 - val_mae: 0.0220 - val_mse: 6.8797e-04\n",
      "\n",
      "Epoch 8/25\n",
      "306/306 - 1s - loss: 0.0411 - mae: 0.0411 - mse: 0.0125 - val_loss: 0.0203 - val_mae: 0.0203 - val_mse: 5.8673e-04\n",
      "\n",
      "Epoch 9/25\n",
      "306/306 - 1s - loss: 0.0364 - mae: 0.0364 - mse: 0.0102 - val_loss: 0.0170 - val_mae: 0.0170 - val_mse: 4.1558e-04\n",
      "\n",
      "Epoch 10/25\n",
      "306/306 - 1s - loss: 0.0311 - mae: 0.0311 - mse: 0.0079 - val_loss: 0.0163 - val_mae: 0.0163 - val_mse: 3.8032e-04\n",
      "\n",
      "Epoch 11/25\n",
      "306/306 - 1s - loss: 0.0263 - mae: 0.0263 - mse: 0.0058 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 2.4874e-04\n",
      "\n",
      "Epoch 12/25\n",
      "306/306 - 1s - loss: 0.0230 - mae: 0.0230 - mse: 0.0045 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 1.7054e-04\n",
      "\n",
      "Epoch 13/25\n",
      "306/306 - 1s - loss: 0.0232 - mae: 0.0232 - mse: 0.0043 - val_loss: 0.0148 - val_mae: 0.0148 - val_mse: 2.9638e-04\n",
      "\n",
      "Epoch 14/25\n",
      "306/306 - 1s - loss: 0.0185 - mae: 0.0185 - mse: 0.0028 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 1.7608e-04\n",
      "\n",
      "Epoch 15/25\n",
      "306/306 - 1s - loss: 0.0156 - mae: 0.0156 - mse: 0.0019 - val_loss: 0.0081 - val_mae: 0.0081 - val_mse: 9.4278e-05\n",
      "\n",
      "Epoch 16/25\n",
      "306/306 - 1s - loss: 0.0141 - mae: 0.0141 - mse: 0.0015 - val_loss: 0.0082 - val_mae: 0.0082 - val_mse: 9.6132e-05\n",
      "\n",
      "Epoch 17/25\n",
      "306/306 - 1s - loss: 0.0119 - mae: 0.0119 - mse: 0.0010 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 1.7952e-04\n",
      "\n",
      "Epoch 18/25\n",
      "306/306 - 1s - loss: 0.0098 - mae: 0.0098 - mse: 6.1903e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 1.7016e-04\n",
      "\n",
      "Best Validation loss of epoch:\n",
      "0.008051001466810703\n",
      "Epoch 1/25\n",
      "306/306 - 1s - loss: 0.0161 - mae: 0.0161 - mse: 3.6336e-04 - val_loss: 0.0252 - val_mae: 0.0252 - val_mse: 9.6359e-04\n",
      "\n",
      "Epoch 2/25\n",
      "306/306 - 1s - loss: 0.0369 - mae: 0.0369 - mse: 0.0103 - val_loss: 0.0365 - val_mae: 0.0365 - val_mse: 0.0018\n",
      "\n",
      "Epoch 3/25\n",
      "306/306 - 1s - loss: 0.0351 - mae: 0.0351 - mse: 0.0095 - val_loss: 0.0250 - val_mae: 0.0250 - val_mse: 9.3309e-04\n",
      "\n",
      "Epoch 4/25\n",
      "306/306 - 1s - loss: 0.0357 - mae: 0.0357 - mse: 0.0100 - val_loss: 0.0343 - val_mae: 0.0343 - val_mse: 0.0016\n",
      "\n",
      "Epoch 5/25\n",
      "306/306 - 1s - loss: 0.0348 - mae: 0.0348 - mse: 0.0094 - val_loss: 0.0361 - val_mae: 0.0361 - val_mse: 0.0018\n",
      "\n",
      "Epoch 6/25\n",
      "306/306 - 1s - loss: 0.0342 - mae: 0.0342 - mse: 0.0092 - val_loss: 0.0323 - val_mae: 0.0323 - val_mse: 0.0015\n",
      "\n",
      "Best Validation loss of epoch:\n",
      "0.025015611201524734\n",
      "Epoch 1/25\n",
      "306/306 - 1s - loss: 0.0027 - mae: 0.0408 - mse: 0.0027 - val_loss: 0.0062 - val_mae: 0.0683 - val_mse: 0.0062\n",
      "\n",
      "Epoch 2/25\n",
      "306/306 - 1s - loss: 0.0111 - mae: 0.0559 - mse: 0.0111 - val_loss: 0.0058 - val_mae: 0.0676 - val_mse: 0.0058\n",
      "\n",
      "Epoch 3/25\n",
      "306/306 - 1s - loss: 0.0105 - mae: 0.0529 - mse: 0.0105 - val_loss: 0.0055 - val_mae: 0.0672 - val_mse: 0.0055\n",
      "\n",
      "Epoch 4/25\n",
      "306/306 - 1s - loss: 0.0100 - mae: 0.0513 - mse: 0.0100 - val_loss: 0.0053 - val_mae: 0.0668 - val_mse: 0.0053\n",
      "\n",
      "Epoch 5/25\n",
      "306/306 - 1s - loss: 0.0096 - mae: 0.0502 - mse: 0.0096 - val_loss: 0.0052 - val_mae: 0.0664 - val_mse: 0.0052\n",
      "\n",
      "Epoch 6/25\n",
      "306/306 - 1s - loss: 0.0093 - mae: 0.0494 - mse: 0.0093 - val_loss: 0.0050 - val_mae: 0.0659 - val_mse: 0.0050\n",
      "\n",
      "Epoch 7/25\n",
      "306/306 - 1s - loss: 0.0090 - mae: 0.0486 - mse: 0.0090 - val_loss: 0.0049 - val_mae: 0.0654 - val_mse: 0.0049\n",
      "\n",
      "Epoch 8/25\n",
      "306/306 - 1s - loss: 0.0087 - mae: 0.0478 - mse: 0.0087 - val_loss: 0.0048 - val_mae: 0.0648 - val_mse: 0.0048\n",
      "\n",
      "Epoch 9/25\n",
      "306/306 - 1s - loss: 0.0085 - mae: 0.0470 - mse: 0.0085 - val_loss: 0.0047 - val_mae: 0.0642 - val_mse: 0.0047\n",
      "\n",
      "Epoch 10/25\n",
      "306/306 - 1s - loss: 0.0082 - mae: 0.0462 - mse: 0.0082 - val_loss: 0.0046 - val_mae: 0.0635 - val_mse: 0.0046\n",
      "\n",
      "Epoch 11/25\n",
      "306/306 - 1s - loss: 0.0079 - mae: 0.0453 - mse: 0.0079 - val_loss: 0.0045 - val_mae: 0.0628 - val_mse: 0.0045\n",
      "\n",
      "Epoch 12/25\n",
      "306/306 - 1s - loss: 0.0077 - mae: 0.0445 - mse: 0.0077 - val_loss: 0.0044 - val_mae: 0.0621 - val_mse: 0.0044\n",
      "\n",
      "Epoch 13/25\n",
      "306/306 - 1s - loss: 0.0074 - mae: 0.0437 - mse: 0.0074 - val_loss: 0.0043 - val_mae: 0.0613 - val_mse: 0.0043\n",
      "\n",
      "Epoch 14/25\n",
      "306/306 - 1s - loss: 0.0072 - mae: 0.0428 - mse: 0.0072 - val_loss: 0.0041 - val_mae: 0.0605 - val_mse: 0.0041\n",
      "\n",
      "Epoch 15/25\n",
      "306/306 - 1s - loss: 0.0069 - mae: 0.0420 - mse: 0.0069 - val_loss: 0.0040 - val_mae: 0.0597 - val_mse: 0.0040\n",
      "\n",
      "Epoch 16/25\n",
      "306/306 - 1s - loss: 0.0067 - mae: 0.0411 - mse: 0.0067 - val_loss: 0.0039 - val_mae: 0.0589 - val_mse: 0.0039\n",
      "\n",
      "Epoch 17/25\n",
      "306/306 - 1s - loss: 0.0065 - mae: 0.0402 - mse: 0.0065 - val_loss: 0.0038 - val_mae: 0.0580 - val_mse: 0.0038\n",
      "\n",
      "Epoch 18/25\n",
      "306/306 - 1s - loss: 0.0062 - mae: 0.0394 - mse: 0.0062 - val_loss: 0.0037 - val_mae: 0.0572 - val_mse: 0.0037\n",
      "\n",
      "Epoch 19/25\n",
      "306/306 - 1s - loss: 0.0060 - mae: 0.0385 - mse: 0.0060 - val_loss: 0.0036 - val_mae: 0.0563 - val_mse: 0.0036\n",
      "\n",
      "Epoch 20/25\n",
      "306/306 - 1s - loss: 0.0058 - mae: 0.0376 - mse: 0.0058 - val_loss: 0.0035 - val_mae: 0.0554 - val_mse: 0.0035\n",
      "\n",
      "Epoch 21/25\n",
      "306/306 - 1s - loss: 0.0055 - mae: 0.0367 - mse: 0.0055 - val_loss: 0.0034 - val_mae: 0.0545 - val_mse: 0.0034\n",
      "\n",
      "Epoch 22/25\n",
      "306/306 - 1s - loss: 0.0053 - mae: 0.0358 - mse: 0.0053 - val_loss: 0.0033 - val_mae: 0.0536 - val_mse: 0.0033\n",
      "\n",
      "Epoch 23/25\n",
      "306/306 - 1s - loss: 0.0051 - mae: 0.0350 - mse: 0.0051 - val_loss: 0.0032 - val_mae: 0.0527 - val_mse: 0.0032\n",
      "\n",
      "Epoch 24/25\n",
      "306/306 - 1s - loss: 0.0049 - mae: 0.0341 - mse: 0.0049 - val_loss: 0.0031 - val_mae: 0.0518 - val_mse: 0.0031\n",
      "\n",
      "Epoch 25/25\n",
      "306/306 - 1s - loss: 0.0047 - mae: 0.0332 - mse: 0.0047 - val_loss: 0.0030 - val_mae: 0.0509 - val_mse: 0.0030\n",
      "\n",
      "Best Validation loss of epoch:\n",
      "0.0029747493099421263\n",
      "Epoch 1/25\n",
      "306/306 - 1s - loss: 2.8455e-04 - mae: 0.0125 - mse: 2.8455e-04 - val_loss: 0.0028 - val_mae: 0.0486 - val_mse: 0.0028\n",
      "\n",
      "Epoch 2/25\n",
      "306/306 - 1s - loss: 0.0042 - mae: 0.0237 - mse: 0.0042 - val_loss: 0.0020 - val_mae: 0.0392 - val_mse: 0.0020\n",
      "\n",
      "Epoch 3/25\n",
      "306/306 - 1s - loss: 0.0043 - mae: 0.0236 - mse: 0.0043 - val_loss: 0.0019 - val_mae: 0.0384 - val_mse: 0.0019\n",
      "\n",
      "Epoch 4/25\n",
      "306/306 - 1s - loss: 0.0050 - mae: 0.0272 - mse: 0.0050 - val_loss: 0.0017 - val_mae: 0.0370 - val_mse: 0.0017\n",
      "\n",
      "Epoch 5/25\n",
      "306/306 - 1s - loss: 0.0041 - mae: 0.0247 - mse: 0.0041 - val_loss: 0.0012 - val_mae: 0.0310 - val_mse: 0.0012\n",
      "\n",
      "Epoch 6/25\n",
      "306/306 - 1s - loss: 0.0037 - mae: 0.0248 - mse: 0.0037 - val_loss: 0.0012 - val_mae: 0.0308 - val_mse: 0.0012\n",
      "\n",
      "Epoch 7/25\n",
      "306/306 - 1s - loss: 0.0037 - mae: 0.0253 - mse: 0.0037 - val_loss: 7.6197e-04 - val_mae: 0.0243 - val_mse: 7.6197e-04\n",
      "\n",
      "Epoch 8/25\n",
      "306/306 - 1s - loss: 0.0032 - mae: 0.0255 - mse: 0.0032 - val_loss: 7.8868e-04 - val_mae: 0.0248 - val_mse: 7.8868e-04\n",
      "\n",
      "Epoch 9/25\n",
      "306/306 - 1s - loss: 0.0032 - mae: 0.0260 - mse: 0.0032 - val_loss: 5.9555e-04 - val_mae: 0.0214 - val_mse: 5.9555e-04\n",
      "\n",
      "Epoch 10/25\n",
      "306/306 - 1s - loss: 0.0026 - mae: 0.0243 - mse: 0.0026 - val_loss: 4.7893e-04 - val_mae: 0.0189 - val_mse: 4.7893e-04\n",
      "\n",
      "Epoch 11/25\n",
      "306/306 - 1s - loss: 0.0022 - mae: 0.0218 - mse: 0.0022 - val_loss: 4.0584e-04 - val_mae: 0.0171 - val_mse: 4.0584e-04\n",
      "\n",
      "Epoch 12/25\n",
      "306/306 - 1s - loss: 0.0018 - mae: 0.0195 - mse: 0.0018 - val_loss: 3.5127e-04 - val_mae: 0.0159 - val_mse: 3.5127e-04\n",
      "\n",
      "Epoch 13/25\n",
      "306/306 - 1s - loss: 0.0011 - mae: 0.0140 - mse: 0.0011 - val_loss: 2.0488e-04 - val_mae: 0.0119 - val_mse: 2.0488e-04\n",
      "\n",
      "Epoch 14/25\n",
      "306/306 - 1s - loss: 5.8400e-04 - mae: 0.0099 - mse: 5.8400e-04 - val_loss: 1.2467e-04 - val_mae: 0.0092 - val_mse: 1.2467e-04\n",
      "\n",
      "Epoch 15/25\n",
      "306/306 - 1s - loss: 2.6067e-04 - mae: 0.0071 - mse: 2.6067e-04 - val_loss: 7.2248e-05 - val_mae: 0.0069 - val_mse: 7.2248e-05\n",
      "\n",
      "Epoch 16/25\n",
      "306/306 - 1s - loss: 9.7679e-05 - mae: 0.0050 - mse: 9.7679e-05 - val_loss: 5.1191e-05 - val_mae: 0.0058 - val_mse: 5.1191e-05\n",
      "\n",
      "Epoch 17/25\n",
      "306/306 - 1s - loss: 3.8517e-05 - mae: 0.0037 - mse: 3.8517e-05 - val_loss: 4.2335e-05 - val_mae: 0.0053 - val_mse: 4.2335e-05\n",
      "\n",
      "Epoch 18/25\n",
      "306/306 - 1s - loss: 2.0649e-05 - mae: 0.0030 - mse: 2.0649e-05 - val_loss: 4.2561e-05 - val_mae: 0.0053 - val_mse: 4.2561e-05\n",
      "\n",
      "Epoch 19/25\n",
      "306/306 - 1s - loss: 1.4321e-05 - mae: 0.0025 - mse: 1.4321e-05 - val_loss: 4.5744e-05 - val_mae: 0.0055 - val_mse: 4.5744e-05\n",
      "\n",
      "Epoch 20/25\n",
      "306/306 - 1s - loss: 1.1598e-05 - mae: 0.0023 - mse: 1.1598e-05 - val_loss: 4.5099e-05 - val_mae: 0.0054 - val_mse: 4.5099e-05\n",
      "\n",
      "Best Validation loss of epoch:\n",
      "4.233549043419771e-05\n",
      "100%|██████████| 5/5 [01:16<00:00, 15.37s/trial, best loss: 4.233549043419771e-05]\n",
      "Evaluation of best performing model:\n",
      "213/213 [==============================] - 1s 4ms/step - loss: 0.0031 - mae: 0.0495 - mse: 0.0031\n",
      "[0.0030588838271796703, 0.04954308643937111, 0.0030588838271796703]\n",
      "Best Performing Model Hyper-Parameters:\n",
      "{'Dense': 2, 'LSTM': 3, 'loss': 1, 'optimizer': 0}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from hyperas import optim\n",
    "    from hyperopt import Trials, tpe\n",
    "\n",
    "    best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name = 'BlackBox')\n",
    "                                          \n",
    "    X_train, y_train, X_test, y_test = data()\n",
    "    print('Evaluation of best performing model:')\n",
    "    print(best_model.evaluate(X_test, y_test))\n",
    "    print(\"Best Performing Model Hyper-Parameters:\")\n",
    "    print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    from hyperas import optim\n",
    "    from hyperopt import Trials, tpe\n",
    "\n",
    "    best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name = 'BlackBox')\n",
    "                                          \n",
    "    X_train, y_train, X_test, y_test = data()\n",
    "    print('Evaluation of best performing model:')\n",
    "    print(best_model.evaluate(X_test, y_test))\n",
    "    print(\"Best Performing Model Hyper-Parameters:\")\n",
    "    print(best_run)"
   ]
  }
 ]
}